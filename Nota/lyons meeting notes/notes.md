# notes

RevX
- Saskia meeting 
    - Remove writing standards out of assessment completely (they will assess writing standards as a part of the curriculum.)
        - They are going to use the state assessment rubric for writing
        - We don't need to do this. 
    - Waiting for Saskia to update us on the standards/timeline for the narrowed down version
        - 6 standards, 10-items per standard that need to be doubled up on. 

create spreadsheet to track job postings
- aera job board
- aefp
- appam
- sree
as anything i am applying for posts, add to spreadsheet. 
    - include details about job, job title, date app is due, what is required for submission
    - cv column, teacher statement, diversity statement, etc. 
    - letters from letter writers when submitting, some will reach out for letters later in process
    - writing sample (job paper and job talk)
        - could use time use for early deadline
    - letters of interest and ones looking for post phd job
    - send letter writers that are tailored for letter writers

LST To-Do
- Rename variables: See Codebook
- Label variables: Entire Survey Questions
- Add value labels: Response options
- Run frequencies on all variables to make sure nothing is weird
    - Flag weirdos
    - Check the "i've never smoked" with "i've smoked 3 packs a week" questions (inconsistencies in data)
        - Seems like this would be a flag for that substance. 
- Look into what kinds of missingness could credibly code for
    - -7= no responses in survey
    - -5= didn't answer single response
    - -3= student moved
- Do it in Stata first...then the team will transfer to SPSS
    - Output should just be easily digestible. 

Looking forward: 
- Look in the Cornell Center Baseline Survey codebook to learn how to combine items in a construct (Youth Surveys Instruments Folder)
    - O:\PSP\HS-LST\Instruments\Youth Surveys & Measures\Measures, Examples, Notes\Cornell Center Baseline Survey Codebook.pdf
    - Run frequencies to make sure all items in scale are "well-behaved" - non-zero variance, not too many people on the ceiling, etc.   
        - Do we want to standardize each item before creating scale so that each item contributes equally to the scale? 
        - Run reliability on raw items v. scaled items (cohen's r and std. item)
            - Tells you what the reliability would have been had you standardized...
            - Are they similar or different? If different, then we need to decide what to do. 
    - Create new variable to be "scaled" version 
        - Average or sum across items to create scaled value for each observation
    - 6 items in scale, missing data on 2, take average

Meeting w/Saskia 5/26
- 
